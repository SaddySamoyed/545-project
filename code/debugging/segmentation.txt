现在, 我从一个 batch of 20 (image_path, caption) pairs 中提取出了 caption 中的关键词, 以及它对应的可 segmentation 的 class. 
这个关系我们存成了一个 list of dicts.

caption_data = [
{'tables': 'dining table', 'chairs': 'chair'},
{'man': 'person', 'desserts': 'cake'},
{'telephone booth': 'bench', 'man': 'person'},
{'kitchen': 'potted plant'},
{'child': 'person', 'woman': 'person'},
{'man': 'person'},
{'clock': 'clock', 'table': 'dining table'},
{'bus': 'bus', 'people': 'person'},
{'bicycle': 'bicycle'},
{'people': 'person', 'food truck': 'truck'},
{'person': 'person'},
{'person': 'person', 'fork': 'fork', 'knife': 'knife'},
{'kitchen': 'potted plant', 'table': 'dining table', 'chairs': 'chair'},
{'kitchen': 'potted plant', 'cabinets': 'potted plant', 'dishwasher': 'microwave', 'sink': 'sink', 'refrigerator': 'refrigerator'},
{'chef': 'person', 'food': 'banana'},
{'adults': 'person', 'laptop computers': 'laptop'},
{'men': 'person', 'table': 'dining table', 'food': 'banana'},
{'man': 'person', 'vegetables': 'broccoli'},
{'chefs': 'person'},
{'table': 'dining table', 'flowers': 'vase'}
]

现在, 对第 i 个 (img_path, img_ID, caption, caption_id) in enumerate(image_caption_pairs): 我们取 img_path i 和它对应的 (同 index) 的 caption_data[i], 用 yolov8 来 segmentation 这个 img i 上的 classes. 比如说, 在 image 1 中, 我们 segment 'dining table' 和 'chair'. 
把 mask 保存为 masks/img_ID-{...} 


对于单个图片的这一处理, 我们已经写得差不多了, 但也不完全.
代码如下: 

os.makedirs(maskFolder, exist_ok=True)
model = YOLO("yolov8n-seg.pt")

# 对输入图片进行检测（分割）
results = model(input_image_path)

img = cv2.imread(input_image_path)
height, width = img.shape[:2]

# 初始化字典，存储每个关键词的合并 mask（全零矩阵）
combined_masks = {k: np.zeros((height, width), dtype=np.uint8) for k in keywords}
label_detected = []
# 遍历检测结果，提取分割 mask
for result in results:
    if result.masks is not None:
        # 遍历每个检测结果
        for i in range(len(result.boxes)):
            # 获取类别索引和对应标签
            class_id = int(result.boxes.cls[i])
            label = model.names[class_id]
            if label in keywords:
                label_detected.append(label)
                # 获取当前检测对应的 mask（结果为 tensor）
                mask = result.masks.data[i].cpu().numpy()
                # 二值化 mask（阈值可调整）
                mask = (mask > 0.2).astype(np.uint8) * 255
                # 若 mask 尺寸与原图不同，则调整大小
                if mask.shape[0] != height or mask.shape[1] != width:
                    mask = cv2.resize(mask, (width, height), interpolation=cv2.INTER_NEAREST)
                # 合并同一类别的 mask（按位或操作）
                combined_masks[label] = cv2.bitwise_or(combined_masks[label], mask)

# 保存每个关键词对应的 mask 图片

for label, mask in combined_masks.items():
    mask_path = f"mask_{label}.png"
    output_image_path = "" # please write it
    cv2.imwrite(output_image_path, mask)
    print(f"Saved mask for '{label}' as {output_image_path}")



 请你改为对整个 batch 逐一进行, 并保存 masks.




 非常好! 现在我需要你做一件额外的事情:
 如果这个 mask 是全黑的 (即 yolo 并没有检测到, 那么就删除这个 mask 的 图片, 并且, 同时删除 caption_data 中对应的 key-value map)
 比如: 对于 image 1, 对应的 caption_data 是 {'tables': 'dining table', 'chairs': 'chair'}, 如果我们检测到的 'chair' 的 mask 是全黑的(或者像素非常少), 那么我们就删除这一条 'chairs': 'chair' 这个 pair 从而 caption_data 的这一条变为 {'tables': 'dining table'}